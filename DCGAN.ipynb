{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of beep boop.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LJWpPHtJWcX"
      },
      "source": [
        "Handling all the imports and setting up cuda runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjVcng2y4mFJ"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchvision import transforms, utils\r\n",
        "\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "# Device configuration\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZd7U9EIJzN3"
      },
      "source": [
        "# The size of batches used for training and generation\r\n",
        "batch_size = 100\r\n",
        "\r\n",
        "# The dimension of the noise vector used for generation\r\n",
        "noise_dim = 100"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbZ-pVssJJX_"
      },
      "source": [
        "Loading the training data and establishing the real target vector and fake target vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2axHujPGJFfQ"
      },
      "source": [
        "t = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5,), (0.5,))])\r\n",
        "\r\n",
        "train_dataset = torchvision.datasets.MNIST('/files/', train=True, download=True, transform=t)\r\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,  batch_size=batch_size, shuffle=True)\r\n",
        "\r\n",
        "real_target = torch.ones(batch_size).to(device)\r\n",
        "smoothed_real_target = torch.ones(batch_size).to(device) * 0.9\r\n",
        "fake_target = torch.zeros(batch_size).to(device)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEYhD_lI6ABJ"
      },
      "source": [
        "def weights_init(m):\r\n",
        "    classname = m.__class__.__name__\r\n",
        "    if classname.find('Conv') != -1:\r\n",
        "        nn.init.normal_(m.weight.data, 0.0, .04)\r\n",
        "    elif classname.find('BatchNorm') != -1:\r\n",
        "        nn.init.normal_(m.weight.data, 1.0, .04)\r\n",
        "        nn.init.constant_(m.bias.data, 0)\r\n",
        "\r\n",
        "\r\n",
        "class Generator(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(Generator, self).__init__()\r\n",
        "    self.conv1 = nn.ConvTranspose2d(noise_dim, 256, kernel_size=7, bias=False)\r\n",
        "    self.conv2 = nn.ConvTranspose2d(256, 256, kernel_size=4, stride=2, padding=1, bias=False)\r\n",
        "    self.conv3 = nn.ConvTranspose2d(256, 1, kernel_size=4, stride=2, padding=1, bias=False)\r\n",
        "    self.batch1 = nn.BatchNorm2d(256)\r\n",
        "    self.batch2 = nn.BatchNorm2d(256)\r\n",
        "  \r\n",
        "  def forward(self, x):\r\n",
        "    x = F.relu(self.batch1(self.conv1(x.reshape(-1, noise_dim, 1, 1))))\r\n",
        "    x = F.relu(self.batch2(self.conv2(x)))\r\n",
        "    x = torch.tanh(self.conv3(x))\r\n",
        "    return x\r\n",
        "\r\n",
        "class Discriminator(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(Discriminator, self).__init__()\r\n",
        "    self.conv1 = nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1, bias=False)\r\n",
        "    self.batch1 = nn.BatchNorm2d(32)\r\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1, bias=False)\r\n",
        "    self.batch2 = nn.BatchNorm2d(64)\r\n",
        "    self.fc1 = nn.Linear(3136, 1, bias=False)\r\n",
        "  \r\n",
        "  def forward(self, x):\r\n",
        "    x = F.leaky_relu(self.batch1(self.conv1(x)), 0.2)\r\n",
        "    x = F.leaky_relu(self.batch2(self.conv2(x)), 0.2).reshape(-1, 3136)\r\n",
        "    x = torch.sigmoid(self.fc1(x))\r\n",
        "    return x\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzdzsFdeJpTF"
      },
      "source": [
        "G = Generator().to(device)\r\n",
        "D = Discriminator().to(device)\r\n",
        "\r\n",
        "G.apply(weights_init)\r\n",
        "D.apply(weights_init)\r\n",
        "\r\n",
        "# loss function\r\n",
        "criterion = nn.BCELoss() \r\n",
        "\r\n",
        "# optimizer\r\n",
        "lr = 0.0002\r\n",
        "optimizerG = optim.Adam(G.parameters(), lr = lr, betas=(0.5, 0.999))\r\n",
        "optimizerD = optim.Adam(D.parameters(), lr = lr/4, betas=(0.5, 0.999))\r\n",
        "\r\n",
        "print(G)\r\n",
        "print(D)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9rHcBS5Cjgi"
      },
      "source": [
        "\r\n",
        "def train_Generator(x):\r\n",
        "    G.zero_grad()\r\n",
        "\r\n",
        "    inputs = Variable(torch.randn(batch_size, noise_dim).to(device))\r\n",
        "    labels = Variable(torch.ones(batch_size, 1).to(device))\r\n",
        "\r\n",
        "    G_output = G(inputs)\r\n",
        "    D_output = D(G_output)\r\n",
        "    loss = criterion(D_output, labels)\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "    optimizerG.step()\r\n",
        "        \r\n",
        "    return loss.data.item()\r\n",
        "\r\n",
        "def train_Discriminator(x):\r\n",
        "    D.zero_grad()\r\n",
        "\r\n",
        "    # training discriminator on real data\r\n",
        "    real_input, real_labels = x.view(-1, 784), torch.ones(batch_size, 1)*.9\r\n",
        "    real_input, real_labels = Variable(real_input.to(device).reshape(-1, 1, 28, 28)), Variable(real_labels.to(device))\r\n",
        "\r\n",
        "    D_output = D(real_input)\r\n",
        "    real_loss = criterion(D_output, real_labels)\r\n",
        "\r\n",
        "    # training disciminator on fake data\r\n",
        "    fake_input = Variable(torch.randn(batch_size, noise_dim).to(device))\r\n",
        "    fake_input, fake_labels = G(fake_input), Variable(torch.zeros(batch_size, 1).to(device))\r\n",
        "\r\n",
        "    D_output = D(fake_input)\r\n",
        "    fake_loss = criterion(D_output, fake_labels)\r\n",
        "\r\n",
        "    loss = real_loss + fake_loss\r\n",
        "    loss.backward()\r\n",
        "    optimizerD.step()\r\n",
        "        \r\n",
        "    return  loss.data.item()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPlS2kgmCDFG"
      },
      "source": [
        "n_epoch = 1000\r\n",
        "\r\n",
        "for epoch in range(1, n_epoch+1):           \r\n",
        "    D_losses, G_losses = [], []\r\n",
        "    for batch_idx, x in enumerate(train_loader):\r\n",
        "        D_losses.append(train_Discriminator(x[0]))\r\n",
        "        G_losses.append(train_Generator(x[0]))\r\n",
        "    \r\n",
        "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\r\n",
        "            (epoch), n_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH1vSvWoneOU"
      },
      "source": [
        "import torchvision.utils as vutils\r\n",
        "\r\n",
        "def show():\r\n",
        "  noise = torch.rand(100, 100).to(device)\r\n",
        "  real_batch = G(noise).detach()\r\n",
        "  print(real_batch.shape)\r\n",
        "  plt.figure(figsize=(10,10))\r\n",
        "  plt.axis(\"off\")\r\n",
        "  plt.title(\"Generated Images\")\r\n",
        "  plt.imshow(np.transpose(vutils.make_grid(real_batch.to(device)[:100], nrow=10, padding=2, normalize=True).cpu(),(1,2,0)))\r\n",
        "\r\n",
        "show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}